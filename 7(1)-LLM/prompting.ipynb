{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53cd899e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jimin/anaconda3/envs/cot/bin/pip\", line 11, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/jimin/anaconda3/envs/cot/lib/python3.9/site-packages/pip/_internal/cli/main.py\", line 79, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/Users/jimin/anaconda3/envs/cot/lib/python3.9/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/Users/jimin/anaconda3/envs/cot/lib/python3.9/site-packages/pip/_internal/cli/base_command.py\", line 236, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/Users/jimin/anaconda3/envs/cot/lib/python3.9/site-packages/pip/_internal/cli/req_command.py\", line 177, in handle_pip_version_check\n",
      "    session = self._build_session(\n",
      "  File \"/Users/jimin/anaconda3/envs/cot/lib/python3.9/site-packages/pip/_internal/cli/req_command.py\", line 122, in _build_session\n",
      "    session = PipSession(\n",
      "  File \"/Users/jimin/anaconda3/envs/cot/lib/python3.9/site-packages/pip/_internal/network/session.py\", line 342, in __init__\n",
      "    self.headers[\"User-Agent\"] = user_agent()\n",
      "  File \"/Users/jimin/anaconda3/envs/cot/lib/python3.9/site-packages/pip/_internal/network/session.py\", line 182, in user_agent\n",
      "    rustc_output = subprocess.check_output(\n",
      "  File \"/Users/jimin/anaconda3/envs/cot/lib/python3.9/subprocess.py\", line 424, in check_output\n",
      "    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "  File \"/Users/jimin/anaconda3/envs/cot/lib/python3.9/subprocess.py\", line 507, in run\n",
      "    stdout, stderr = process.communicate(input, timeout=timeout)\n",
      "  File \"/Users/jimin/anaconda3/envs/cot/lib/python3.9/subprocess.py\", line 1134, in communicate\n",
      "    stdout, stderr = self._communicate(input, endtime, timeout)\n",
      "  File \"/Users/jimin/anaconda3/envs/cot/lib/python3.9/subprocess.py\", line 1995, in _communicate\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Users/jimin/anaconda3/envs/cot/lib/python3.9/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!pip install groq python-dotenv numpy tqdm datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "249253df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jimin/anaconda3/envs/cot/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "load_dotenv()\n",
    "random.seed(0)\n",
    "\n",
    "client = Groq()\n",
    "gsm8k_dataset = load_dataset(\"gsm8k\", \"main\")\n",
    "\n",
    "gsm8k_train = gsm8k_dataset[\"train\"]\n",
    "gsm8k_test  = gsm8k_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4d75bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_using_Llama(\n",
    "        prompt: str,\n",
    "        model: str = \"llama3-8b-8192\",\n",
    "        temperature: float = 0.3\n",
    "    ):\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant that solves math problems.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            model=model,\n",
    "            temperature=temperature, ### ÏàòÏ†ïÌï¥ÎèÑ Îê©ÎãàÎã§!\n",
    "            stream=False\n",
    "        )\n",
    "        return chat_completion.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"API call error: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef65ad3",
   "metadata": {},
   "source": [
    "#### ÏùëÎãµ Ïûò ÎÇòÏò§ÎäîÏßÄ ÌôïÏù∏Ìï¥Î≥¥Í∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a37fad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm excited to help you with any math problems you may have. What kind of math are you working on? Do you have a specific problem you're stuck on or a concept you're trying to understand? Let me know and I'll do my best to assist you!\n"
     ]
    }
   ],
   "source": [
    "response = generate_response_using_Llama(\n",
    "    prompt=\"Hello world!\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988803ae",
   "metadata": {},
   "source": [
    "#### GSM8K Îç∞Ïù¥ÌÑ∞ÏÖã ÌôïÏù∏Ìï¥Î≥¥Í∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbd177eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Question]\n",
      "Janet‚Äôs ducks lay 16 eggs per day\n",
      " She eats three for breakfast every morning and bakes muffins for her friends every day with four\n",
      " She sells the remainder at the farmers' market daily for $2 per fresh duck egg\n",
      " How much in dollars does she make every day at the farmers' market?\n",
      "====================================================================================================\n",
      "[Answer]\n",
      "Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\n",
      "She makes 9 * 2 = $<<9*2=18>>18 every day at the farmer‚Äôs market.\n",
      "#### 18\n"
     ]
    }
   ],
   "source": [
    "print(\"[Question]\")\n",
    "for l in gsm8k_test['question'][0].split(\".\"):\n",
    "    print(l)\n",
    "print(\"=\"*100)\n",
    "print(\"[Answer]\")\n",
    "print(gsm8k_test['answer'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaabe66c",
   "metadata": {},
   "source": [
    "#### Util Ìï®ÏàòÎì§\n",
    "- extract_final_answer: LLMÏùò ÏùëÎãµÏùÑ parseÌïòÏó¨ ÏµúÏ¢Ö Í≤∞Í≥ºÎßå Ï∂îÏ∂ú (Ï†ïÎãµÍ≥º ÎπÑÍµêÌïòÍ∏∞ ÏúÑÌï¥)\n",
    "- run_benchmark_test: Î≤§ÏπòÎßàÌÅ¨ ÌÖåÏä§Ìä∏\n",
    "- save_final_result: Í≤∞Í≥ºÎ¨º Ï†úÏ∂úÏùÑ ÏúÑÌïú Ìï®Ïàò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40c10811",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ÏàòÏ†ïÌï¥ÎèÑ Îê©ÎãàÎã§!\n",
    "def extract_final_answer(response: str):\n",
    "    regex = r\"(?:Answer:|Model response:)\\s*\\$?([0-9,]+)\\b|([0-9,]+)\\s*(meters|cups|miles|minutes)\"\n",
    "    matches = re.finditer(regex, response, re.MULTILINE)\n",
    "    results = [match.group(1) if match.group(1) else match.group(2).replace(\",\", \"\") for match in matches]\n",
    "\n",
    "    if len(results) == 0:\n",
    "        additional_regex = r\"\\$?([0-9,]+)\"\n",
    "        additional_matches = re.finditer(additional_regex, response, re.MULTILINE)\n",
    "        results.extend([match.group(1).replace(\",\", \"\") for match in additional_matches])\n",
    "\n",
    "    return results[-1] if results else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e3a05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def run_benchmark_test(\n",
    "        dataset,\n",
    "        prompt,\n",
    "        model: str = \"llama3-8b-8192\",\n",
    "        num_samples: int = 50,\n",
    "        VERBOSE: bool = False,\n",
    "    ):\n",
    "    correct = 0\n",
    "    total   = 0\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(min(num_samples, len(dataset)))):\n",
    "        question = dataset[i][\"question\"]\n",
    "        correct_answer = float(re.findall(r'\\d+(?:\\.\\d+)?', dataset[i][\"answer\"].split('####')[-1])[0])\n",
    "\n",
    "        if isinstance(prompt, list):\n",
    "            response_list = []\n",
    "            for p in prompt:\n",
    "                response = generate_response_using_Llama(\n",
    "                    prompt=p.format(question=question),\n",
    "                    model=model\n",
    "                )\n",
    "                response_list.append(response)\n",
    "        else:\n",
    "            response = generate_response_using_Llama(\n",
    "                prompt=prompt.format(question=question),\n",
    "                model=model\n",
    "            )\n",
    "            response_list = [response]\n",
    "\n",
    "        predicted_answer = None  # Ï¥àÍ∏∞Ìôî\n",
    "\n",
    "        if response_list:\n",
    "            if VERBOSE:\n",
    "                print(\"=\"*50)\n",
    "                for idx, res in enumerate(response_list):\n",
    "                    print(f\"[Response {idx+1}]\\n{res}\\n\")\n",
    "                print(\"=\"*50)\n",
    "\n",
    "            # Í∞Å ÏùëÎãµÏóêÏÑú ÏµúÏ¢Ö Ïà´Ïûê Ï∂îÏ∂ú\n",
    "            extracted_answers = [extract_final_answer(r) for r in response_list]\n",
    "            try:\n",
    "                extracted_answers = [\n",
    "                    float(ans.replace(\",\", \"\")) for ans in extracted_answers if ans is not None\n",
    "                ]\n",
    "            except Exception as e:\n",
    "                if VERBOSE:\n",
    "                    print(f\"‚ö†Ô∏è Error during prediction: {e}\")\n",
    "                predicted_answer = None\n",
    "\n",
    "            if len(extracted_answers) == 0:\n",
    "                response = generate_response_using_Llama(\n",
    "                    prompt=prompt.format(question=question),\n",
    "                    model=model,\n",
    "                    temperature=0.2\n",
    "                )\n",
    "                response_list = [response]\n",
    "                extracted_answers = [extract_final_answer(r) for r in response_list]\n",
    "                try:\n",
    "                    extracted_answers = [\n",
    "                        float(ans.replace(\",\", \"\")) for ans in extracted_answers if ans is not None\n",
    "                    ]\n",
    "                except Exception as e:\n",
    "                    if VERBOSE:\n",
    "                        print(f\"‚ö†Ô∏è Error during prediction: {e}\")\n",
    "                    predicted_answer = None\n",
    "\n",
    "            \n",
    "            if extracted_answers:\n",
    "                # üéØ Îã§ÏàòÍ≤∞ Ï†ÅÏö©\n",
    "                most_common = Counter(extracted_answers).most_common(1)[0][0]\n",
    "                predicted_answer = most_common\n",
    "            else:\n",
    "                predicted_answer = None\n",
    "\n",
    "            is_correct = abs(predicted_answer - correct_answer) < 1e-5 if predicted_answer is not None else False\n",
    "\n",
    "            if is_correct:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "            results.append({\n",
    "                'question': question,\n",
    "                'correct_answer': correct_answer,\n",
    "                'predicted_answer': predicted_answer,\n",
    "                'response': response_list if isinstance(prompt, list) else response,\n",
    "                'correct': is_correct\n",
    "            })\n",
    "\n",
    "            if (i + 1) % 5 == 0:\n",
    "                current_acc = correct / total if total > 0 else 0\n",
    "                print(f\"Progress: [{i+1}/{num_samples}]\")\n",
    "                print(f\"Current Acc.: [{current_acc:.2%}]\")\n",
    "\n",
    "    return results, correct / total if total > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e63f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_final_result(results: List[Dict[str, Any]], accuracy: float, filename: str) -> None:\n",
    "    result_str = f\"====== ACCURACY: {accuracy} ======\\n\\n\"\n",
    "    result_str += f\"[Details]\\n\"\n",
    "    \n",
    "    for idx, result in enumerate(results):\n",
    "        result_str += f\"Question {idx+1}: {result['question']}\\n\"\n",
    "        result_str += f\"Correct Answer: {result['correct_answer']}\\n\"\n",
    "        result_str += f\"Predicted Answer: {result['predicted_answer']}\\n\"\n",
    "        result_str += f\"Correct: {result['correct']}\\n\\n\"\n",
    "    \n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(result_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c498f9ed",
   "metadata": {},
   "source": [
    "#### Direct prompting with few-shot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f430083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_direct_prompt(num_examples: int = 3) -> str:\n",
    "    train_dataset = gsm8k_train\n",
    "\n",
    "    sampled_indices = random.sample(\n",
    "        [i for i in range(len(train_dataset['question']))],\n",
    "        num_examples\n",
    "    )\n",
    "\n",
    "    prompt = \"Instruction:\\nSolve the following mathematical question and generate ONLY the answer after a tag, 'Answer:' without any rationale.\\n\"\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        cur_question = train_dataset['question'][i]\n",
    "        cur_answer = train_dataset['answer'][i].split(\"####\")[-1].strip()\n",
    "\n",
    "        prompt += f\"\\n[Example {i+1}]\\n\"\n",
    "        prompt += f\"Question:\\n{cur_question}\\n\"\n",
    "        prompt += f\"Answer:{cur_answer}\\n\"\n",
    "\n",
    "    prompt += \"\\nQuestion:\\n{question}\\nAnswer:\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68a2b484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:02<00:02,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/10]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:05<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/10]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Ïñ¥Îñ§ Î∞©ÏãùÏúºÎ°ú Ï†ÄÏû•ÎêòÎäîÏßÄ ÌôïÏù∏Ìï¥Î≥¥ÏÑ∏Ïöî!\n",
    "PROMPT = construct_direct_prompt(3)\n",
    "VERBOSE = False\n",
    "\n",
    "results, accuracy = run_benchmark_test(\n",
    "    dataset=gsm8k_test,\n",
    "    prompt=PROMPT,\n",
    "    VERBOSE=VERBOSE,\n",
    "    num_samples=10\n",
    ")\n",
    "save_final_result(results, accuracy, \"example.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41874896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 5/50 [00:02<00:22,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [40.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 10/50 [00:04<00:19,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [30.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [00:07<00:20,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [00:12<00:37,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [25.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [00:26<01:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [24.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [00:39<00:53,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [00:53<00:39,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [17.14%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [01:06<00:26,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [15.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [01:19<00:13,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [17.78%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:33<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 5/50 [00:13<02:02,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 10/50 [00:26<01:40,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [00:38<01:27,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [00:50<01:14,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [25.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [01:03<01:04,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [24.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [01:17<00:54,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [26.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [01:30<00:40,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [22.86%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [01:44<00:26,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [01:57<00:13,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [02:11<00:00,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 5/50 [00:13<02:01,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [40.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 10/50 [00:27<01:49,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [00:40<01:36,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [13.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [00:54<01:23,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [01:08<01:08,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [24.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [01:22<00:54,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [26.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [01:36<00:41,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [22.86%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [01:48<00:25,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [22.50%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [02:02<00:13,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [02:15<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [20.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: 0 shot, 3 shot, 5 shot direct promptingÏùÑ ÌÜµÌï¥ Î≤§ÏπòÎßàÌÅ¨ ÌÖåÏä§Ìä∏Î•º Ìïú ÌõÑ, Í∞ÅÍ∞Å direct_prompting_{shot: int}.txtÎ°ú Ï†ÄÏû•Ìï¥Ï£ºÏÑ∏Ïöî!\n",
    "# ÏòàÏãú: shotÏù¥ 5Ïù∏ Í≤ΩÏö∞ direct_prompting_5.txt\n",
    "# Ìï≠ÏÉÅ num_samples=50 ÏûÖÎãàÎã§!\n",
    "\n",
    "### 0 shot direct prompting\n",
    "PROMPT = construct_direct_prompt(0)\n",
    "VERBOSE = False\n",
    "\n",
    "results, accuracy = run_benchmark_test(\n",
    "    dataset=gsm8k_test,\n",
    "    prompt=PROMPT,\n",
    "    VERBOSE=VERBOSE,\n",
    "    num_samples=50\n",
    ")\n",
    "save_final_result(results, accuracy, \"direct_prompting_0.txt\")\n",
    "\n",
    "### 3 shot direct prompting\n",
    "PROMPT = construct_direct_prompt(3)\n",
    "VERBOSE = False\n",
    "\n",
    "results, accuracy = run_benchmark_test(\n",
    "    dataset=gsm8k_test,\n",
    "    prompt=PROMPT,\n",
    "    VERBOSE=VERBOSE,\n",
    "    num_samples=50\n",
    ")\n",
    "save_final_result(results, accuracy, \"direct_prompting_3.txt\")\n",
    "\n",
    "### 5 shot direct prompting\n",
    "PROMPT = construct_direct_prompt(5)\n",
    "VERBOSE = False\n",
    "\n",
    "results, accuracy = run_benchmark_test(\n",
    "    dataset=gsm8k_test,\n",
    "    prompt=PROMPT,\n",
    "    VERBOSE=VERBOSE,\n",
    "    num_samples=50\n",
    ")\n",
    "save_final_result(results, accuracy, \"direct_prompting_5.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fd21d1",
   "metadata": {},
   "source": [
    "### Chain-of-Thought prompting with few-shot example\n",
    "```text\n",
    "[Question]\n",
    "Janet‚Äôs ducks lay 16 eggs per day\n",
    " She eats three for breakfast every morning and bakes muffins for her friends every day with four\n",
    " She sells the remainder at the farmers' market daily for $2 per fresh duck egg\n",
    " How much in dollars does she make every day at the farmers' market?\n",
    "====================================================================================================\n",
    "[Answer]\n",
    "Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\n",
    "She makes 9 * 2 = $<<9*2=18>>18 every day at the farmer‚Äôs market.\n",
    "#### 18\n",
    "```\n",
    "\n",
    "[Answer] ÏïÑÎûòÏùò Ï†ïÎãµÏùÑ ÎèÑÏ∂úÌïòÎäî Í≥ºÏ†ïÏùÑ ÏòàÏãúÎ°ú Îã¨ÏïÑÏ£ºÎ©¥ CoTÏùò few shotÏù¥ ÎêòÍ≤†Ï£†?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73a989e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_CoT_prompt(num_examples: int = 3) -> str:\n",
    "    train_dataset = gsm8k_train\n",
    "\n",
    "    sampled_indices = random.sample(\n",
    "        [i for i in range(len(train_dataset['question']))],\n",
    "        num_examples\n",
    "    )\n",
    "    prompt = \"Instruction:\\nGenerate the answer for the given mathematical question with step-by-step rationale toward the answer.\"\n",
    "\n",
    "    for i in range(num_examples):\n",
    "        cur_question = gsm8k_train['question'][sampled_indices[i]]\n",
    "        cur_answer = gsm8k_train['answer'][sampled_indices[i]]\n",
    "        prompt += f\"\\n[Example {i+1}]\\n\"\n",
    "        prompt += f\"Question:\\n{cur_question}\\n\"\n",
    "        prompt += f\"Output:{cur_answer}\\n\"\n",
    "\n",
    "    prompt += f\"\\n\\n[Example {num_examples+1}]\\n\"\n",
    "    prompt += \"Question:\\n{question}\\n\"\n",
    "    prompt += \"#### \"\n",
    "\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36225084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "Generate the answer for the given mathematical question with step-by-step rationale toward the answer.\n",
      "[Example 1]\n",
      "Question:\n",
      "Lena played video games for 3.5 hours last weekend. Her brother played 17 minutes more than she did. How many minutes together did Lena and her brother play video games last weekend?\n",
      "Output:Lena = 3.5 hours = 210 minutes\n",
      "Brother = 210 + 17 = <<210+17=227>>227 minutes\n",
      "210 + 227 = <<210+227=437>>437 minutes\n",
      "Together, Lena and her brother played 437 minutes of video games.\n",
      "#### 437\n",
      "\n",
      "[Example 2]\n",
      "Question:\n",
      "There are 3 rows of people relaxing at the beach. The first row is made up of 24 people until 3 people get up to wade in the water. 5 people from the second row, which originally held 20 people, go to join them. The third row is made up of 18 people. How many people are left relaxing on the beach?\n",
      "Output:In the first row, there are now 24 ‚Äì 3 = <<24-3=21>>21 people.\n",
      "In the second row, there are now 20 ‚Äì 5 = <<20-5=15>>15 people.\n",
      "So in total there are 21 in the first row + 15 in the second row + 18 in the third row = <<21+15+18=54>>54 people.\n",
      "#### 54\n",
      "\n",
      "[Example 3]\n",
      "Question:\n",
      "Mary needs school supplies. She has 6 classes and needs 1 folder for each class. She also needs 3 pencils for each class. She decides that for every 6 pencils she should have 1 eraser. She also needs a set of paints for an art class.  Folders cost $6, pencils cost $2, and erasers cost $1. If she spends $80, how much did the set of paints cost in dollars?\n",
      "Output:Mary needs 6*1= <<6*1=6>>6 folders.\n",
      "Mary needs 6*3= <<6*3=18>>18 pencils.\n",
      "Mary needs 18/6= <<18/6=3>>3 erasers.\n",
      "Mary spends 6*6= $<<6*6=36>>36 on folders.\n",
      "Mary spends 18*2= $<<18*2=36>>36 on pencils.\n",
      "Mary spends 3*1= $<<3*1=3>>3 on erasers.\n",
      "Mary spends 36+36+3= $<<36+36+3=75>>75 on all the supplies except the paints.\n",
      "Mary spends 80-75= $<<80-75=5>>5 on the paint set.\n",
      "#### 5\n",
      "\n",
      "[Example 4]\n",
      "Question:\n",
      "There are 235 books in a library. On Tuesday, 227 books are taken out. On Thursday, 56 books are brought back and 35 books are taken out again on Friday. How many books are there now?\n",
      "Output:On Tuesday, 227 books were taken, so there are 235 - 227= <<235-227=8>>8 books left.\n",
      "56 books were brought back on Thursday, so there are 8 + 56 = <<8+56=64>>64 books in the library.\n",
      "Finally, 35 books are taken out on Friday, leaving 64 - 35 = <<29=29>>29 books available.\n",
      "#### 29\n",
      "\n",
      "[Example 5]\n",
      "Question:\n",
      "Melony makes $21 of profit every time she sells 3 shirts and four times as much profit when she sells two pairs of sandals. How much profit will she make if she sells 7 shirts and 3 pairs of sandals?\n",
      "Output:Melony makes $21 * 4 = $<<21*4=84>>84 of profit for two pairs of sandals.\n",
      "Melony makes $84 / 2 pairs = $<<84/2=42>>42 of profit per pair of shoes.\n",
      "Melony makes $21 / 3 shirts = $<<21/3=7>>7 of profit per shirt.\n",
      "For seven shirts, Melony will make 7 shirts * $7 = $<<7*7=49>>49 of profit.\n",
      "For three pairs of sandals, Melony will make 3 pairs * $42/pair = $<<3*42=126>>126 of profit.\n",
      "Melony will make a total of $49 + $126 = $<<49+126=175>>175 of profit.\n",
      "#### 175\n",
      "\n",
      "\n",
      "[Example 6]\n",
      "Question:\n",
      "{question}\n",
      "#### \n"
     ]
    }
   ],
   "source": [
    "print(construct_CoT_prompt(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c510586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 5/50 [00:12<01:46,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 10/50 [00:29<02:08,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [00:36<00:53,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [00:44<00:40,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [55.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [00:51<00:29,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [52.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [00:57<00:25,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [53.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [01:14<00:43,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [01:31<00:34,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [57.50%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [01:47<00:16,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [57.78%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [02:05<00:00,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [58.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: 0 shot, 3 shot, 5 shot CoT promptingÏùÑ ÌÜµÌï¥ Î≤§ÏπòÎßàÌÅ¨ ÌÖåÏä§Ìä∏Î•º Ìïú ÌõÑ, Í∞ÅÍ∞Å CoT_prompting_{shot: int}.txtÎ°ú Ï†ÄÏû•Ìï¥Ï£ºÏÑ∏Ïöî!\n",
    "# ÏòàÏãú: shotÏù¥ 5Ïù∏ Í≤ΩÏö∞ CoT_prompting_5.txt\n",
    "# Ìï≠ÏÉÅ num_samples=50 ÏûÖÎãàÎã§!\n",
    "\n",
    "PROMPT = construct_CoT_prompt(0)\n",
    "VERBOSE = False\n",
    "\n",
    "results, accuracy = run_benchmark_test(\n",
    "    dataset=gsm8k_test,\n",
    "    prompt=PROMPT,\n",
    "    VERBOSE=VERBOSE,\n",
    "    num_samples=50\n",
    ")\n",
    "save_final_result(results, accuracy, \"CoT_prompting_0.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac9dfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 5/50 [00:04<00:43,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 10/50 [00:50<05:19,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [01:35<05:18,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [02:18<04:19,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [03:02<03:30,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [03:45<02:51,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [63.33%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [04:27<02:04,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [68.57%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [05:09<01:25,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [62.50%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [05:53<00:43,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [66.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [06:38<00:00,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [68.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### 3 shot CoT prompting\n",
    "PROMPT = construct_CoT_prompt(3)\n",
    "VERBOSE = False\n",
    "\n",
    "results, accuracy = run_benchmark_test(\n",
    "    dataset=gsm8k_test,\n",
    "    prompt=PROMPT,\n",
    "    VERBOSE=VERBOSE,\n",
    "    num_samples=50\n",
    ")\n",
    "save_final_result(results, accuracy, \"CoT_prompting_3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d476d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5 shot CoT prompting\n",
    "PROMPT = construct_CoT_prompt(5)\n",
    "VERBOSE = False\n",
    "\n",
    "results, accuracy = run_benchmark_test(\n",
    "    dataset=gsm8k_test,\n",
    "    prompt=PROMPT,\n",
    "    VERBOSE=True,\n",
    "    num_samples=50\n",
    ")\n",
    "save_final_result(results, accuracy, \"CoT_prompting_5.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c45b54",
   "metadata": {},
   "source": [
    "### Construct your prompt!!\n",
    "\n",
    "Î™©Ìëú: Î≥∏Ïù∏ÎßåÏùò ÌîÑÎ°¨ÌîÑÌä∏Î•º ÌÜµÌï¥ Ï†ïÎãµÎ•†ÏùÑ Îçî ÎÅåÏñ¥Ïò¨Î†§Î≥¥Í∏∞!\n",
    "- gsm8kÏùò train Îç∞Ïù¥ÌÑ∞ÏÖãÏóêÏÑú ÏòàÏãúÎ•º Í∞ÄÏ†∏Ïò® Îã§Ïùå (ÏûêÏú†Î°≠Í≤å!)\n",
    "- Í∑∏ ÏòàÏãúÎì§Ïóê ÎåÄÌïú ÌíÄÏù¥ Í≥ºÏ†ïÏùÑ ÎßåÎì§Ïñ¥Ï£ºÏÑ∏Ïöî!\n",
    "- Î™®Îì† Í≤ÉÎì§Ïù¥ ÏûêÏú†ÏûÖÎãàÎã§! Direct Prompting, CoT PromptingÏùÑ Ìïú Í≤∞Í≥ºÎ≥¥Îã§ Ï†ïÎãµÎ•†Îßå ÎÜíÏúºÎ©¥ ÎèºÏöî."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caec0247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_my_prompt(num_examples: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Construct a few-shot prompt enforcing step-by-step breakdown and answer verification.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a meticulous math tutor. Solve each problem by explicitly breaking it down into smaller subproblems.\\n\"\n",
    "        \"Then verify your answer by recomputing it at the end. Always end your response with '#### [final answer]'.\\n\\n\"\n",
    "    )\n",
    "\n",
    "    sampled_indices = random.sample(range(len(gsm8k_train['question'])), num_examples)\n",
    "\n",
    "    for i, idx in enumerate(sampled_indices):\n",
    "        question = gsm8k_train['question'][idx].strip()\n",
    "        answer = gsm8k_train['answer'][idx].strip()\n",
    "        prompt += f\"[Example {i+1}]\\n\"\n",
    "        prompt += f\"Question:\\n{question}\\n\"\n",
    "        prompt += f\"Answer:\\nLet's break this into parts step-by-step.\\n\"\n",
    "        prompt += f\"{answer}\\n\"\n",
    "        prompt += \"Let's verify the final answer by recomputing it...\\n\"\n",
    "        prompt += f\"{answer.split('####')[0].strip()}\\n{answer.strip()}\\n\\n\"\n",
    "\n",
    "    prompt += f\"[Example {num_examples+1}]\\n\"\n",
    "    prompt += \"Question:\\n{question}\\n\"\n",
    "    prompt += \"Answer:\\nLet's break this into parts step-by-step.\\n\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a90a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 0 shot direct prompting\n",
    "\n",
    "PROMPT = construct_my_prompt(0)\n",
    "VERBOSE = False\n",
    "\n",
    "results, accuracy = run_benchmark_test(\n",
    "    dataset=gsm8k_test,\n",
    "    prompt = PROMPT,\n",
    "    VERBOSE=VERBOSE,\n",
    "    num_samples=50,\n",
    ")\n",
    "save_final_result(results, accuracy, \"My_prompting_0.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d498c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3 shot direct prompting\n",
    "\n",
    "PROMPT = construct_my_prompt(3)\n",
    "VERBOSE = False\n",
    "\n",
    "results, accuracy = run_benchmark_test(\n",
    "    dataset=gsm8k_test,\n",
    "    prompt = PROMPT,\n",
    "    VERBOSE=VERBOSE,\n",
    "    num_samples=50,\n",
    ")\n",
    "save_final_result(results, accuracy, \"My_prompting_3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8451285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 5/50 [01:42<17:35, 23.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [5/50]\n",
      "Current Acc.: [80.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 10/50 [03:55<17:19, 26.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [10/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 15/50 [06:15<15:39, 26.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [15/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [08:29<13:25, 26.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [20/50]\n",
      "Current Acc.: [65.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [10:58<11:27, 27.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [25/50]\n",
      "Current Acc.: [60.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [13:11<08:50, 26.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [30/50]\n",
      "Current Acc.: [66.67%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [15:43<07:03, 28.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [35/50]\n",
      "Current Acc.: [71.43%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [18:16<05:02, 30.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [40/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [20:52<02:47, 33.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [45/50]\n",
      "Current Acc.: [68.89%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [22:58<00:00, 27.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [50/50]\n",
      "Current Acc.: [70.00%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### 5 shot direct prompting\n",
    "\n",
    "PROMPT = construct_my_prompt(5)\n",
    "VERBOSE = False\n",
    "\n",
    "results, accuracy = run_benchmark_test(\n",
    "    dataset=gsm8k_test,\n",
    "    prompt = PROMPT,\n",
    "    VERBOSE=VERBOSE,\n",
    "    num_samples=50,\n",
    ")\n",
    "save_final_result(results, accuracy, \"My_prompting_5.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd837d7",
   "metadata": {},
   "source": [
    "### Î≥¥Í≥†ÏÑú ÏûëÏÑ±ÌïòÍ∏∞\n",
    "#### ÏïÑÎûòÏùò ÎÇ¥Ïö©Ïù¥ Ìè¨Ìï®ÎêòÎ©¥ Îê©ÎãàÎã§!\n",
    "\n",
    "1. Direct Prompting, CoT Prompting, My PromptingÏùÑ 0 shot, 3 shot, 5 shot Ï†ïÎãµÎ•†ÏùÑ ÌëúÎ°ú Î≥¥Ïó¨Ï£ºÏÑ∏Ïöî!\n",
    "2. CoT PromptingÏù¥ Direct PromptingÏóê ÎπÑÌï¥ Ïôú Ï¢ãÏùÑ Ïàò ÏûàÎäîÏßÄÏóê ÎåÄÌï¥ÏÑú ÏÑúÏà†Ìï¥Ï£ºÏÑ∏Ïöî!\n",
    "3. Î≥∏Ïù∏Ïù¥ ÏûëÏÑ±Ìïú ÌîÑÎ°¨ÌîÑÌä∏ Í∏∞Î≤ïÏù¥ CoTÏóê ÎπÑÌï¥ÏÑú Ïôú Îçî Ï¢ãÏùÑ Ïàò ÏûàÎäîÏßÄÏóê ÎåÄÌï¥ÏÑú ÏÑ§Î™ÖÌï¥Ï£ºÏÑ∏Ïöî!\n",
    "4. ÏµúÏ¢ÖÏ†ÅÏúºÎ°ú, `PROMPTING.md`Ïóê Î≥¥Í≥†ÏÑúÎ•º ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
